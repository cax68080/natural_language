{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第1章 文書のベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 単語分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### janomeによる単語分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "mrGYkL-XDsnw",
    "outputId": "19fdcdfe-49aa-4896-8787-5d0a7cea4da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting janome\n",
      "  Downloading Janome-0.4.2-py2.py3-none-any.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 1.4 MB/s \n",
      "\u001b[?25hInstalling collected packages: janome\n",
      "Successfully installed janome-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install janome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GqeYDWsuEI8c"
   },
   "outputs": [],
   "source": [
    "import janome\n",
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HB40aJ1EEh9D",
    "outputId": "ae15cc14-9c64-4c20-ab29-6d198c34fafb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "私/は/秋田/犬/と/三/毛/猫/が/好き/"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "string = '私は秋田犬と三毛猫が好き'\n",
    "for token in t.tokenize(string,wakati=True):\n",
    "  print(token,end='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6s5YhMgHFpRv",
    "outputId": "56696e66-c91f-479f-8d74-f4b2bf1c53d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私', 'は', '土佐犬', 'が', '好き', 'です', '。']\n"
     ]
    }
   ],
   "source": [
    "string = '私は土佐犬が好きです。'\n",
    "words = [token for token in t.tokenize(string,wakati=True)]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語のN-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxALWh3WS-5V",
    "outputId": "e7f52ec1-8da0-4567-f4dc-def8c8f0e291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['私', 'は', '本'], ['は', '本', 'と'], ['本', 'と', 'コーラ'], ['と', 'コーラ', 'が'], ['コーラ', 'が', '好き'], ['が', '好き', 'です'], ['好き', 'です', '。']]\n"
     ]
    }
   ],
   "source": [
    "# 文章から単語のn-gramを返す関数\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "def get_word_n_grams(string,n):\n",
    "  words = [token for token in t.tokenize(string,wakati=True)]\n",
    "  result = []\n",
    "  for index in range(len(words)):\n",
    "    result.append(words[index: index+n])\n",
    "    if index + n >= len(words):\n",
    "      return result\n",
    "\n",
    "print(get_word_n_grams('私は本とコーラが好きです。',3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文字のN-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私', 'は', '本', 'を', '読', 'み', 'な', 'が', 'ら', 'ビ', 'ー', 'ル', 'を', '飲', 'む', 'の', 'が', '好', 'き', 'で', 'す', '。']\n"
     ]
    }
   ],
   "source": [
    "print(list('私は本を読みながらビールを飲むのが好きです。'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私は', 'はビ', 'ビー', 'ール', 'ルを', 'を飲', '飲み', 'みな', 'なが', 'がら', 'ら本', '本を', 'を読', '読み', 'みま', 'ます', 'す。']\n"
     ]
    }
   ],
   "source": [
    "#文章から文字のn-gramを返す関数\n",
    "def get_character_n_grams(string,n):\n",
    "    result = []\n",
    "    for index in range(len(string)):\n",
    "        result.append(string[index: index + n])\n",
    "        if index + n >= len(string):\n",
    "            return result\n",
    "\n",
    "print(get_character_n_grams('私はビールを飲みながら本を読みます。',2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文書ベクトルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "メロスは激怒した。必ず、かの邪智暴虐の王を除かなければならぬと決意した。メロスには政治がわからぬ。メロスは、村の牧人である。笛を吹き、羊と遊んで暮して来た。けれども邪悪に対しては、人一倍に敏感であった。きょう未明メロスは村を出発し、野を越え山越え、十里はなれた此のシラクスの市にやって来た。メロスには父も、母も無い。女房も無い。十六の、内気な妹と二人暮しだ。この妹は、村の或る律気な一牧人を、近々、花婿として迎える事になっていた。結婚式も間近かなのである。メロスは、それゆえ、花嫁の衣裳やら祝宴の御馳走やらを買いに、はるばる市にやって来たのだ。先ず、その品々を買い集め、それから都の大路をぶらぶら歩いた。メロスには竹馬の友があった。セリヌンティウスである。今は此のシラクスの市で、石工をしている。その友を、これから訪ねてみるつもりなのだ。久しく逢わなかったのだから、訪ねて行くのが楽しみである。歩いているうちにメロスは、まちの様子を怪しく思った。ひっそりしている。もう既に日も落ちて、まちの暗いのは当りまえだが、けれども、なんだか、夜のせいばかりでは無く、市全体が、やけに寂しい。のんきなメロスも、だんだん不安になって来た。路で逢った若い衆をつかまえて、何かあったのか、二年まえに此の市に来たときは、夜でも皆が歌をうたって、まちは賑やかであった筈だが、と質問した。若い衆は、首を振って答えなかった。しばらく歩いて老爺に逢い、こんどはもっと、語勢を強くして質問した。老爺は答えなかった。メロスは両手で老爺のからだをゆすぶって質問を重ねた。老爺は、あたりをはばかる低声で、わずか答えた。「王様は、人を殺します。」「なぜ殺すのだ。」「悪心を抱いている、というのですが、誰もそんな、悪心を持っては居りませぬ。」「たくさんの人を殺したのか。」「はい、はじめは王様の妹婿さまを。それから、御自身のお世嗣を。それから、妹さまを。それから、妹さまの御子さまを。それから、皇后さまを。それから、賢臣のアレキス様を。」「おどろいた。国王は乱心か。」「いいえ、乱心ではございませぬ。人を、信ずる事が出来ぬ、というのです。このごろは、臣下の心をも、お疑いになり、少しく派手な暮しをしている者には、人質ひとりずつ差し出すことを命じて居ります。御命令を拒めば十字架にかけられて、殺されます。きょうは、六人殺されました。」聞いて、メロスは激怒した。「呆れた王だ。生かして置けぬ。」メロスは、単純な男であった。買い物を、背負ったままで、のそのそ王城にはいって行った。たちまち彼は、巡邏の警吏に捕縛された。調べられて、メロスの懐中からは短剣が出て来たので、騒ぎが大きくなってしまった。メロスは、王の前に引き出された。「この短刀で何をするつもりであったか。言え！」暴君ディオニスは静かに、けれども威厳を以て問いつめた。その王の顔は蒼白で、眉間の皺は、刻み込まれたように深かった。「市を暴君の手から救うのだ。」とメロスは悪びれずに答えた。「おまえがか？」王は、憫笑した。「仕方の無いやつじゃ。おまえには、わしの孤独がわからぬ。」「言うな！」とメロスは、いきり立って反駁した。「人の心を疑うのは、最も恥ずべき悪徳だ。王は、民の忠誠をさえ疑って居られる。」「疑うのが、正当の心構えなのだと、わしに教えてくれたのは、おまえたちだ。人の心は、あてにならない。人間は、もともと私慾のかたまりさ。信じては、ならぬ。」暴君は落着いて呟き、ほっと溜息をついた。「わしだって、平和を望んでいるのだが。」「なんの為の平和だ。自分の地位を守る為か。」こんどはメロスが嘲笑した。「罪の無い人を殺して、何が平和だ。」「だまれ、下賤の者。」王は、さっと顔を挙げて報いた。「口では、どんな清らかな事でも言える。わしには、人の腹綿の奥底が見え透いてならぬ。おまえだって、いまに、磔になってから、泣いて詫びたって聞かぬぞ。」「ああ、王は悧巧だ。自惚れているがよい。私は、ちゃんと死ぬる覚悟で居るのに。命乞いなど決してしない。ただ、――」と言いかけて、メロスは足もとに視線を落し瞬時ためらい、「ただ、私に情をかけたいつもりなら、処刑までに三日間の日限を与えて下さい。たった一人の妹に、亭主を持たせてやりたいのです。三日のうちに、私は村で結婚式を挙げさせ、必ず、ここへ帰って来ます。」「ばかな。」と暴君は、嗄れた声で低く笑った。「とんでもない嘘を言うわい。逃がした小鳥が帰って来るというのか。」「そうです。帰って来るのです。」メロスは必死で言い張った。「私は約束を守ります。私を、三日間だけ許して下さい。妹が、私の帰りを待っているのだ。そんなに私を信じられないならば、よろしい、この市にセリヌンティウスという石工がいます。私の無二の友人だ。あれを、人質としてここに置いて行こう。私が逃げてしまって、三日目の日暮まで、ここに帰って来なかったら、あの友人を絞め殺して下さい。たのむ、そうして下さい。」それを聞いて王は、残虐な気持で、そっと北叟笑んだ。生意気なことを言うわい。どうせ帰って来ないにきまっている。この嘘つきに騙された振りして、放してやるのも面白い。そうして身代りの男を、三日目に殺してやるのも気味がいい。人は、これだから信じられぬと、わしは悲しい顔して、その身代りの男を磔刑に処してやるのだ。世の中の、正直者とかいう奴輩にうんと見せつけてやりたいものさ。「願いを、聞いた。その身代りを呼ぶがよい。三日目には日没までに帰って来い。おくれたら、その身代りを、きっと殺すぞ。ちょっとおくれて来るがいい。おまえの罪は、永遠にゆるしてやろうぞ。」「なに、何をおっしゃる。」「はは。いのちが大事だったら、おくれて来い。おまえの心は、わかっているぞ。」メロスは口惜しく、地団駄踏んだ。ものも言いたくなくなった。竹馬の友、セリヌンティウスは、深夜、王城に召された。暴君ディオニスの面前で、佳き友と佳き友は、二年ぶりで相逢うた。メロスは、友に一切の事情を語った。セリヌンティウスは無言で首肯き、メロスをひしと抱きしめた。友と友の間は、それでよかった。セリヌンティウスは、縄打たれた。メロスは、すぐに出発した。初夏、満天の星である。メロスはその夜、一睡もせず十里の路を急ぎに急いで、村へ到着したのは、翌る日の午前、陽は既に高く昇って、村人たちは野に出て仕事をはじめていた。メロスの十六の妹も、きょうは兄の代りに羊群の番をしていた。よろめいて歩いて来る兄の、疲労困憊の姿を見つけて驚いた。そうして、うるさく兄に質問を浴びせた。「なんでも無い。」メロスは無理に笑おうと努めた。「市に用事を残して来た。またすぐ市に行かなければならぬ。あす、おまえの結婚式を挙げる。早いほうがよかろう。」妹は頬をあからめた。「うれしいか。綺麗な衣裳も買って来た。さあ、これから行って、村の人たちに知らせて来い。結婚式は、あすだと。」メロスは、また、よろよろと歩き出し、家へ帰って神々の祭壇を飾り、祝宴の席を調え、間もなく床に倒れ伏し、呼吸もせぬくらいの深い眠りに落ちてしまった。眼が覚めたのは夜だった。メロスは起きてすぐ、花婿の家を訪れた。そうして、少し事情があるから、結婚式を明日にしてくれ、と頼んだ。婿の牧人は驚き、それはいけない、こちらには未だ何の仕度も出来ていない、葡萄の季節まで待ってくれ、と答えた。メロスは、待つことは出来ぬ、どうか明日にしてくれ給え、と更に押してたのんだ。婿の牧人も頑強であった。なかなか承諾してくれない。夜明けまで議論をつづけて、やっと、どうにか婿をなだめ、すかして、説き伏せた。結婚式は、真昼に行われた。新郎新婦の、神々への宣誓が済んだころ、黒雲が空を覆い、ぽつりぽつり雨が降り出し、やがて車軸を流すような大雨となった。祝宴に列席していた村人たちは、何か不吉なものを感じたが、それでも、めいめい気持を引きたて、狭い家の中で、むんむん蒸し暑いのも怺え、陽気に歌をうたい、手を拍った。メロスも、満面に喜色を湛え、しばらくは、王とのあの約束をさえ忘れていた。祝宴は、夜に入っていよいよ乱れ華やかになり、人々は、外の豪雨を全く気にしなくなった。メロスは、一生このままここにいたい、と思った。この佳い人たちと生涯暮して行きたいと願ったが、いまは、自分のからだで、自分のものでは無い。ままならぬ事である。メロスは、わが身に鞭打ち、ついに出発を決意した。あすの日没までには、まだ十分の時が在る。ちょっと一眠りして、それからすぐに出発しよう、と考えた。その頃には、雨も小降りになっていよう。少しでも永くこの家に愚図愚図とどまっていたかった。メロスほどの男にも、やはり未練の情というものは在る。今宵呆然、歓喜に酔っているらしい花嫁に近寄り、「おめでとう。私は疲れてしまったから、ちょっとご免こうむって眠りたい。眼が覚めたら、すぐに市に出かける。大切な用事があるのだ。私がいなくても、もうおまえには優しい亭主があるのだから、決して寂しい事は無い。おまえの兄の、一ばんきらいなものは、人を疑う事と、それから、嘘をつく事だ。おまえも、それは、知っているね。亭主との間に、どんな秘密でも作ってはならぬ。おまえに言いたいのは、それだけだ。おまえの兄は、たぶん偉い男なのだから、おまえもその誇りを持っていろ。」花嫁は、夢見心地で首肯いた。メロスは、それから花婿の肩をたたいて、「仕度の無いのはお互さまさ。私の家にも、宝といっては、妹と羊だけだ。他には、何も無い。全部あげよう。もう一つ、メロスの弟になったことを誇ってくれ。」花婿は揉み手して、てれていた。メロスは笑って村人たちにも会釈して、宴席から立ち去り、羊小屋にもぐり込んで、死んだように深く眠った。眼が覚めたのは翌る日の薄明の頃である。メロスは跳ね起き、南無三、寝過したか、いや、まだまだ大丈夫、これからすぐに出発すれば、約束の刻限までには十分間に合う。きょうは是非とも、あの王に、人の信実の存するところを見せてやろう。そうして笑って磔の台に上ってやる。メロスは、悠々と身仕度をはじめた。雨も、いくぶん小降りになっている様子である。身仕度は出来た。さて、メロスは、ぶるんと両腕を大きく振って、雨中、矢の如く走り出た。私は、今宵、殺される。殺される為に走るのだ。身代りの友を救う為に走るのだ。王の奸佞邪智を打ち破る為に走るのだ。走らなければならぬ。そうして、私は殺される。若い時から名誉を守れ。さらば、ふるさと。若いメロスは、つらかった。幾度か、立ちどまりそうになった。えい、えいと大声挙げて自身を叱りながら走った。村を出て、野を横切り、森をくぐり抜け、隣村に着いた頃には、雨も止み、日は高く昇って、そろそろ暑くなって来た。メロスは額の汗をこぶしで払い、ここまで来れば大丈夫、もはや故郷への未練は無い。妹たちは、きっと佳い夫婦になるだろう。私には、いま、なんの気がかりも無い筈だ。まっすぐに王城に行き着けば、それでよいのだ。そんなに急ぐ必要も無い。ゆっくり歩こう、と持ちまえの呑気さを取り返し、好きな小歌をいい声で歌い出した。ぶらぶら歩いて二里行き三里行き、そろそろ全里程の半ばに到達した頃、降って湧いた災難、メロスの足は、はたと、とまった。見よ、前方の川を。きのうの豪雨で山の水源地は氾濫し、濁流滔々と下流に集り、猛勢一挙に橋を破壊し、どうどうと響きをあげる激流が、木葉微塵に橋桁を跳ね飛ばしていた。彼は茫然と、立ちすくんだ。あちこちと眺めまわし、また、声を限りに呼びたててみたが、繋舟は残らず浪に浚われて影なく、渡守りの姿も見えない。流れはいよいよ、ふくれ上り、海のようになっている。メロスは川岸にうずくまり、男泣きに泣きながらゼウスに手を挙げて哀願した。「ああ、鎮めたまえ、荒れ狂う流れを！時は刻々に過ぎて行きます。太陽も既に真昼時です。あれが沈んでしまわぬうちに、王城に行き着くことが出来なかったら、あの佳い友達が、私のために死ぬのです。」濁流は、メロスの叫びをせせら笑う如く、ますます激しく躍り狂う。浪は浪を呑み、捲き、煽り立て、そうして時は、刻一刻と消えて行く。今はメロスも覚悟した。泳ぎ切るより他に無い。ああ、神々も照覧あれ！濁流にも負けぬ愛と誠の偉大な力を、いまこそ発揮して見せる。メロスは、ざんぶと流れに飛び込み、百匹の大蛇のようにのた打ち荒れ狂う浪を相手に、必死の闘争を開始した。満身の力を腕にこめて、押し寄せ渦巻き引きずる流れを、なんのこれしきと掻きわけ掻きわけ、めくらめっぽう獅子奮迅の人の子の姿には、神も哀れと思ったか、ついに憐愍を垂れてくれた。押し流されつつも、見事、対岸の樹木の幹に、すがりつく事が出来たのである。ありがたい。メロスは馬のように大きな胴震いを一つして、すぐにまた先きを急いだ。一刻といえども、むだには出来ない。陽は既に西に傾きかけている。ぜいぜい荒い呼吸をしながら峠をのぼり、のぼり切って、ほっとした時、突然、目の前に一隊の山賊が躍り出た。「待て。」「何をするのだ。私は陽の沈まぬうちに王城へ行かなければならぬ。放せ。」「どっこい放さぬ。持ちもの全部を置いて行け。」「私にはいのちの他には何も無い。その、たった一つの命も、これから王にくれてやるのだ。」「その、いのちが欲しいのだ。」「さては、王の命令で、ここで私を待ち伏せしていたのだな。」山賊たちは、ものも言わず一斉に棍棒を振り挙げた。メロスはひょいと、からだを折り曲げ、飛鳥の如く身近かの一人に襲いかかり、その棍棒を奪い取って、「気の毒だが正義のためだ！」と猛然一撃、たちまち、三人を殴り倒し、残る者のひるむ隙に、さっさと走って峠を下った。一気に峠を駈け降りたが、流石に疲労し、折から午後の灼熱の太陽がまともに、かっと照って来て、メロスは幾度となく眩暈を感じ、これではならぬ、と気を取り直しては、よろよろ二、三歩あるいて、ついに、がくりと膝を折った。立ち上る事が出来ぬのだ。天を仰いで、くやし泣きに泣き出した。ああ、あ、濁流を泳ぎ切り、山賊を三人も撃ち倒し韋駄天、ここまで突破して来たメロスよ。真の勇者、メロスよ。今、ここで、疲れ切って動けなくなるとは情無い。愛する友は、おまえを信じたばかりに、やがて殺されなければならぬ。おまえは、稀代の不信の人間、まさしく王の思う壺だぞ、と自分を叱ってみるのだが、全身萎えて、もはや芋虫ほどにも前進かなわぬ。路傍の草原にごろりと寝ころがった。身体疲労すれば、精神も共にやられる。もう、どうでもいいという、勇者に不似合いな不貞腐れた根性が、心の隅に巣喰った。私は、これほど努力したのだ。約束を破る心は、みじんも無かった。神も照覧、私は精一ぱいに努めて来たのだ。動けなくなるまで走って来たのだ。私は不信の徒では無い。ああ、できる事なら私の胸を截ち割って、真紅の心臓をお目に掛けたい。愛と信実の血液だけで動いているこの心臓を見せてやりたい。けれども私は、この大事な時に、精も根も尽きたのだ。私は、よくよく不幸な男だ。私は、きっと笑われる。私の一家も笑われる。私は友を欺いた。中途で倒れるのは、はじめから何もしないのと同じ事だ。ああ、もう、どうでもいい。これが、私の定った運命なのかも知れない。セリヌンティウスよ、ゆるしてくれ。君は、いつでも私を信じた。私も君を、欺かなかった。私たちは、本当に佳い友と友であったのだ。いちどだって、暗い疑惑の雲を、お互い胸に宿したことは無かった。いまだって、君は私を無心に待っているだろう。ああ、待っているだろう。ありがとう、セリヌンティウス。よくも私を信じてくれた。それを思えば、たまらない。友と友の間の信実は、この世で一ばん誇るべき宝なのだからな。セリヌンティウス、私は走ったのだ。君を欺くつもりは、みじんも無かった。信じてくれ！私は急ぎに急いでここまで来たのだ。濁流を突破した。山賊の囲みからも、するりと抜けて一気に峠を駈け降りて来たのだ。私だから、出来たのだよ。ああ、この上、私に望み給うな。放って置いてくれ。どうでも、いいのだ。私は負けたのだ。だらしが無い。笑ってくれ。王は私に、ちょっとおくれて来い、と耳打ちした。おくれたら、身代りを殺して、私を助けてくれると約束した。私は王の卑劣を憎んだ。けれども、今になってみると、私は王の言うままになっている。私は、おくれて行くだろう。王は、ひとり合点して私を笑い、そうして事も無く私を放免するだろう。そうなったら、私は、死ぬよりつらい。私は、永遠に裏切者だ。地上で最も、不名誉の人種だ。セリヌンティウスよ、私も死ぬぞ。君と一緒に死なせてくれ。君だけは私を信じてくれるにちがい無い。いや、それも私の、ひとりよがりか？ああ、もういっそ、悪徳者として生き伸びてやろうか。村には私の家が在る。羊も居る。妹夫婦は、まさか私を村から追い出すような事はしないだろう。正義だの、信実だの、愛だの、考えてみれば、くだらない。人を殺して自分が生きる。それが人間世界の定法ではなかったか。ああ、何もかも、ばかばかしい。私は、醜い裏切り者だ。どうとも、勝手にするがよい。やんぬる哉。――四肢を投げ出して、うとうと、まどろんでしまった。ふと耳に、潺々、水の流れる音が聞えた。そっと頭をもたげ、息を呑んで耳をすました。すぐ足もとで、水が流れているらしい。よろよろ起き上って、見ると、岩の裂目から滾々と、何か小さく囁きながら清水が湧き出ているのである。その泉に吸い込まれるようにメロスは身をかがめた。水を両手で掬って、一くち飲んだ。ほうと長い溜息が出て、夢から覚めたような気がした。歩ける。行こう。肉体の疲労恢復と共に、わずかながら希望が生れた。義務遂行の希望である。わが身を殺して、名誉を守る希望である。斜陽は赤い光を、樹々の葉に投じ、葉も枝も燃えるばかりに輝いている。日没までには、まだ間がある。私を、待っている人があるのだ。少しも疑わず、静かに期待してくれている人があるのだ。私は、信じられている。私の命なぞは、問題ではない。死んでお詫び、などと気のいい事は言って居られぬ。私は、信頼に報いなければならぬ。いまはただその一事だ。走れ！メロス。私は信頼されている。私は信頼されている。先刻の、あの悪魔の囁きは、あれは夢だ。悪い夢だ。忘れてしまえ。五臓が疲れているときは、ふいとあんな悪い夢を見るものだ。メロス、おまえの恥ではない。やはり、おまえは真の勇者だ。再び立って走れるようになったではないか。ありがたい！私は、正義の士として死ぬ事が出来るぞ。ああ、陽が沈む。ずんずん沈む。待ってくれ、ゼウスよ。私は生れた時から正直な男であった。正直な男のままにして死なせて下さい。路行く人を押しのけ、跳ねとばし、メロスは黒い風のように走った。野原で酒宴の、その宴席のまっただ中を駈け抜け、酒宴の人たちを仰天させ、犬を蹴とばし、小川を飛び越え、少しずつ沈んでゆく太陽の、十倍も早く走った。一団の旅人と颯っとすれちがった瞬間、不吉な会話を小耳にはさんだ。「いまごろは、あの男も、磔にかかっているよ。」ああ、その男、その男のために私は、いまこんなに走っているのだ。その男を死なせてはならない。急げ、メロス。おくれてはならぬ。愛と誠の力を、いまこそ知らせてやるがよい。風態なんかは、どうでもいい。メロスは、いまは、ほとんど全裸体であった。呼吸も出来ず、二度、三度、口から血が噴き出た。見える。はるか向うに小さく、シラクスの市の塔楼が見える。塔楼は、夕陽を受けてきらきら光っている。「ああ、メロス様。」うめくような声が、風と共に聞えた。「誰だ。」メロスは走りながら尋ねた。「フィロストラトスでございます。貴方のお友達セリヌンティウス様の弟子でございます。」その若い石工も、メロスの後について走りながら叫んだ。「もう、駄目でございます。むだでございます。走るのは、やめて下さい。もう、あの方をお助けになることは出来ません。」「いや、まだ陽は沈まぬ。」「ちょうど今、あの方が死刑になるところです。ああ、あなたは遅かった。おうらみ申します。ほんの少し、もうちょっとでも、早かったなら！」「いや、まだ陽は沈まぬ。」メロスは胸の張り裂ける思いで、赤く大きい夕陽ばかりを見つめていた。走るより他は無い。「やめて下さい。走るのは、やめて下さい。いまはご自分のお命が大事です。あの方は、あなたを信じて居りました。刑場に引き出されても、平気でいました。王様が、さんざんあの方をからかっても、メロスは来ます、とだけ答え、強い信念を持ちつづけている様子でございました。」「それだから、走るのだ。信じられているから走るのだ。間に合う、間に合わぬは問題でないのだ。人の命も問題でないのだ。私は、なんだか、もっと恐ろしく大きいものの為に走っているのだ。ついて来い！フィロストラトス。」「ああ、あなたは気が狂ったか。それでは、うんと走るがいい。ひょっとしたら、間に合わぬものでもない。走るがいい。」言うにや及ぶ。まだ陽は沈まぬ。最後の死力を尽して、メロスは走った。メロスの頭は、からっぽだ。何一つ考えていない。ただ、わけのわからぬ大きな力にひきずられて走った。陽は、ゆらゆら地平線に没し、まさに最後の一片の残光も、消えようとした時、メロスは疾風の如く刑場に突入した。間に合った。「待て。その人を殺してはならぬ。メロスが帰って来た。約束のとおり、いま、帰って来た。」と大声で刑場の群衆にむかって叫んだつもりであったが、喉がつぶれて嗄れた声が幽かに出たばかり、群衆は、ひとりとして彼の到着に気がつかない。すでに磔の柱が高々と立てられ、縄を打たれたセリヌンティウスは、徐々に釣り上げられてゆく。メロスはそれを目撃して最後の勇、先刻、濁流を泳いだように群衆を掻きわけ、掻きわけ、「私だ、刑吏！殺されるのは、私だ。メロスだ。彼を人質にした私は、ここにいる！」と、かすれた声で精一ぱいに叫びながら、ついに磔台に昇り、釣り上げられてゆく友の両足に、齧りついた。群衆は、どよめいた。あっぱれ。ゆるせ、と口々にわめいた。セリヌンティウスの縄は、ほどかれたのである。「セリヌンティウス。」メロスは眼に涙を浮べて言った。「私を殴れ。ちから一ぱいに頬を殴れ。私は、途中で一度、悪い夢を見た。君が若し私を殴ってくれなかったら、私は君と抱擁する資格さえ無いのだ。殴れ。」セリヌンティウスは、すべてを察した様子で首肯き、刑場一ぱいに鳴り響くほど音高くメロスの右頬を殴った。殴ってから優しく微笑み、「メロス、私を殴れ。同じくらい音高く私の頬を殴れ。私はこの三日の間、たった一度だけ、ちらと君を疑った。生れて、はじめて君を疑った。君が私を殴ってくれなければ、私は君と抱擁できない。」メロスは腕に唸りをつけてセリヌンティウスの頬を殴った。「ありがとう、友よ。」二人同時に言い、ひしと抱き合い、それから嬉し泣きにおいおい声を放って泣いた。群衆の中からも、歔欷の声が聞えた。暴君ディオニスは、群衆の背後から二人の様を、まじまじと見つめていたが、やがて静かに二人に近づき、顔をあからめて、こう言った。「おまえらの望みは叶ったぞ。おまえらは、わしの心に勝ったのだ。信実とは、決して空虚な妄想ではなかった。どうか、わしをも仲間に入れてくれまいか。どうか、わしの願いを聞き入れて、おまえらの仲間の一人にしてほしい。」どっと群衆の間に、歓声が起った。「万歳、王様万歳。」ひとりの少女が、緋のマントをメロスに捧げた。メロスは、まごついた。佳き友は、気をきかせて教えてやった。「メロス、君は、まっぱだかじゃないか。早くそのマントを着るがいい。この可愛い娘さんは、メロスの裸体を、皆に見られるのが、たまらなく口惜しいのだ。」勇者は、ひどく赤面した。\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# テキストファイルを読み込む\n",
    "import chardet\n",
    "\n",
    "def get_string_from_file(filename):\n",
    "    with open(filename,'rb') as f:\n",
    "        d = f.read()\n",
    "        e = chardet.detect(d)['encoding']\n",
    "        # 推定できなかった場合はUTF-8に設定する\n",
    "        if e == None:\n",
    "            e = 'UTF-8'\n",
    "        return d.decode(e)\n",
    "\n",
    "print(get_string_from_file('melos.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'私': 1, 'は': 1, 'ビール': 1, 'を': 2, '飲み': 1, 'ながら': 1, '本': 1, '読む': 1, '。': 1}\n",
      "{'私': 1, 'は': 1, '本': 1, 'を': 2, '読み': 1, 'ながら': 1, 'ビール': 1, '飲む': 1, '。': 1}\n",
      "{'私': 1, 'は': 1, 'ビール': 1, 'を': 2, '飲ん': 1, 'で': 1, '本': 1, '読む': 1, 'の': 1, 'が': 1, '好き': 1, 'です': 1, '。': 1}\n"
     ]
    }
   ],
   "source": [
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "def get_bag_of_words(document):\n",
    "    t = Tokenizer()\n",
    "\n",
    "    result_dict = {}\n",
    "\n",
    "    words = [token for token in t.tokenize(document,wakati=True)]\n",
    "    \n",
    "    for word in words:\n",
    "        if word not in result_dict:\n",
    "            result_dict[word]=1\n",
    "        else:\n",
    "            result_dict[word] += 1\n",
    "    return result_dict\n",
    "\n",
    "document1 = '私はビールを飲みながら本を読む。'\n",
    "document2 = '私は本を読みながらビールを飲む。'\n",
    "document3 = '私はビールを飲んで本を読むのが好きです。'\n",
    "\n",
    "print(get_bag_of_words(document1))\n",
    "print(get_bag_of_words(document2))\n",
    "print(get_bag_of_words(document3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'私': 1, 'は': 2, '秋田': 3, '犬': 4, 'が': 5, '大好き': 6, 'です': 7, '。': 8, 'の': 9, '好き': 10, 'な': 11, '苦手': 12, 'より': 13, '猫': 14, 'ほう': 15}\n"
     ]
    }
   ],
   "source": [
    "# 素性の辞書を作成する関数\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "def make_dictionary(documents):\n",
    "    result_dict = {}\n",
    "    index = 1\n",
    "    for adocument in documents:\n",
    "        words = [token for token in t.tokenize(adocument,wakati=True)]\n",
    "        for word in words:\n",
    "            if word not in result_dict:\n",
    "                result_dict[word] = index\n",
    "                index += 1\n",
    "    return result_dict\n",
    "\n",
    "document1 = '私は秋田犬が大好きです。私の好きな犬は秋田犬です。'\n",
    "document2 = '私は犬が苦手です。犬より猫のほうが好きです。'\n",
    "documents = [document1,document2]\n",
    "dict = make_dictionary(documents) \n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#用例ベクトルを作成する関数make_BOW_vectors\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "def make_BOW_vectors(documents,dictionary):\n",
    "    result_vectors = []\n",
    "    \n",
    "    for adocument in documents:\n",
    "        avector = {}\n",
    "        words = [token for token in t.tokenize(adocument,wakati=True)]\n",
    "        for entry in dictionary:\n",
    "            avector[dictionary[entry]] = 0\n",
    "        for word in words:\n",
    "            avector[dictionary[word]] += 1\n",
    "        result_vectors.append(avector)\n",
    "    return result_vectors\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'私': 1, 'は': 2, '秋田': 3, '犬': 4, 'が': 5, '大好き': 6, 'です': 7, '。': 8, 'の': 9, '好き': 10, 'な': 11, '苦手': 12, 'より': 13, '猫': 14, 'ほう': 15}\n",
      "[{1: 2, 2: 2, 3: 2, 4: 3, 5: 1, 6: 1, 7: 2, 8: 2, 9: 1, 10: 1, 11: 1, 12: 0, 13: 0, 14: 0, 15: 0}, {1: 1, 2: 1, 3: 0, 4: 2, 5: 2, 6: 0, 7: 2, 8: 2, 9: 1, 10: 1, 11: 0, 12: 1, 13: 1, 14: 1, 15: 1}]\n"
     ]
    }
   ],
   "source": [
    "document1 = '私は秋田犬が大好きです。私の好きな犬は秋田犬です。'\n",
    "document2 = '私は犬が苦手です。犬より猫のほうが好きです。'\n",
    "documents = [document1,document2]\n",
    "dict = make_dictionary(documents) \n",
    "print(dict)\n",
    "print(make_BOW_vectors(documents,dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{1: 76, 2: 267, 3: 2, 4: 60, 5: 214, 6: 458, 7: 2, 8: 555, 9: 1, 10: 2, 11: 1, 12: 303, 13: 19, 14: 220, 15: 1, 16: 7, 17: 16, 18: 19, 19: 36, 20: 74, 21: 2, 22: 207, 23: 1, 24: 97, 25: 3, 26: 9, 27: 4, 28: 91, 29: 19, 30: 1, 31: 1, 32: 5, 33: 1, 34: 4, 35: 237, 36: 19, 37: 5, 38: 1, 39: 1, 40: 1, 41: 1, 42: 11, 43: 4, 44: 1, 45: 5, 46: 3, 47: 1, 48: 1, 49: 6, 50: 2, 51: 1, 52: 3, 53: 3, 54: 11, 55: 2, 56: 1, 57: 74, 58: 1, 59: 20, 60: 1, 61: 3, 62: 1, 63: 36, 64: 12, 65: 8, 66: 30, 67: 95, 68: 12, 69: 1, 70: 4, 71: 1, 72: 7, 73: 10, 74: 1, 75: 4, 76: 5, 77: 1, 78: 15, 79: 16, 80: 20, 81: 6, 82: 1, 83: 25, 84: 11, 85: 1, 86: 3, 87: 2, 88: 3, 89: 4, 90: 1, 91: 2, 92: 1, 93: 1, 94: 21, 95: 1, 96: 1, 97: 9, 98: 1, 99: 1, 100: 2, 101: 5, 102: 2, 103: 18, 104: 15, 105: 5, 106: 3, 107: 35, 108: 4, 109: 2, 110: 3, 111: 5, 112: 1, 113: 1, 114: 9, 115: 27, 116: 4, 117: 1, 118: 4, 119: 3, 120: 4, 121: 1, 122: 3, 123: 1, 124: 9, 125: 4, 126: 9, 127: 2, 128: 2, 129: 1, 130: 4, 131: 2, 132: 5, 133: 1, 134: 5, 135: 2, 136: 1, 137: 1, 138: 2, 139: 1, 140: 1, 141: 1, 142: 3, 143: 1, 144: 2, 145: 1, 146: 11, 147: 2, 148: 2, 149: 10, 150: 2, 151: 2, 152: 1, 153: 1, 154: 2, 155: 4, 156: 1, 157: 2, 158: 6, 159: 2, 160: 4, 161: 1, 162: 2, 163: 2, 164: 1, 165: 1, 166: 2, 167: 3, 168: 1, 169: 1, 170: 1, 171: 1, 172: 1, 173: 9, 174: 2, 175: 62, 176: 4, 177: 8, 178: 13, 179: 62, 180: 1, 181: 2, 182: 2, 183: 1, 184: 6, 185: 9, 186: 2, 187: 1, 188: 2, 189: 3, 190: 3, 191: 1, 192: 1, 193: 4, 194: 4, 195: 6, 196: 2, 197: 2, 198: 8, 199: 1, 200: 1, 201: 1, 202: 1, 203: 1, 204: 1, 205: 4, 206: 1, 207: 1, 208: 2, 209: 1, 210: 6, 211: 1, 212: 11, 213: 1, 214: 1, 215: 7, 216: 1, 217: 2, 218: 1, 219: 1, 220: 6, 221: 3, 222: 4, 223: 2, 224: 1, 225: 7, 226: 1, 227: 2, 228: 1, 229: 1, 230: 4, 231: 10, 232: 7, 233: 18, 234: 4, 235: 3, 236: 1, 237: 1, 238: 1, 239: 1, 240: 12, 241: 1, 242: 1, 243: 5, 244: 1, 245: 5, 246: 2, 247: 2, 248: 2, 249: 4, 250: 1, 251: 1, 252: 1, 253: 8, 254: 1, 255: 1, 256: 1, 257: 6, 258: 1, 259: 1, 260: 2, 261: 5, 262: 2, 263: 2, 264: 1, 265: 5, 266: 1, 267: 12, 268: 6, 269: 3, 270: 3, 271: 1, 272: 1, 273: 1, 274: 4, 275: 1, 276: 1, 277: 1, 278: 1, 279: 13, 280: 1, 281: 3, 282: 2, 283: 1, 284: 6, 285: 20, 286: 2, 287: 1, 288: 1, 289: 1, 290: 1, 291: 8, 292: 1, 293: 5, 294: 1, 295: 1, 296: 3, 297: 2, 298: 1, 299: 2, 300: 2, 301: 1, 302: 1, 303: 3, 304: 3, 305: 1, 306: 9, 307: 1, 308: 1, 309: 2, 310: 19, 311: 10, 312: 1, 313: 23, 314: 3, 315: 1, 316: 1, 317: 1, 318: 11, 319: 1, 320: 1, 321: 2, 322: 2, 323: 3, 324: 4, 325: 3, 326: 1, 327: 4, 328: 6, 329: 6, 330: 1, 331: 2, 332: 1, 333: 2, 334: 1, 335: 1, 336: 1, 337: 1, 338: 5, 339: 2, 340: 2, 341: 2, 342: 1, 343: 1, 344: 1, 345: 1, 346: 1, 347: 1, 348: 12, 349: 5, 350: 2, 351: 1, 352: 1, 353: 1, 354: 8, 355: 15, 356: 1, 357: 1, 358: 5, 359: 76, 360: 1, 361: 5, 362: 2, 363: 2, 364: 1, 365: 1, 366: 2, 367: 3, 368: 4, 369: 2, 370: 4, 371: 2, 372: 1, 373: 1, 374: 1, 375: 1, 376: 3, 377: 9, 378: 1, 379: 12, 380: 12, 381: 2, 382: 1, 383: 1, 384: 8, 385: 3, 386: 3, 387: 1, 388: 7, 389: 3, 390: 1, 391: 10, 392: 6, 393: 9, 394: 2, 395: 1, 396: 4, 397: 1, 398: 2, 399: 2, 400: 1, 401: 1, 402: 4, 403: 5, 404: 2, 405: 1, 406: 6, 407: 2, 408: 6, 409: 1, 410: 1, 411: 6, 412: 2, 413: 1, 414: 1, 415: 2, 416: 4, 417: 3, 418: 2, 419: 18, 420: 1, 421: 5, 422: 1, 423: 8, 424: 10, 425: 1, 426: 1, 427: 1, 428: 2, 429: 2, 430: 1, 431: 1, 432: 1, 433: 1, 434: 1, 435: 1, 436: 2, 437: 1, 438: 6, 439: 1, 440: 6, 441: 6, 442: 1, 443: 11, 444: 4, 445: 1, 446: 1, 447: 1, 448: 1, 449: 3, 450: 1, 451: 1, 452: 2, 453: 1, 454: 10, 455: 2, 456: 1, 457: 3, 458: 5, 459: 7, 460: 3, 461: 5, 462: 2, 463: 2, 464: 3, 465: 1, 466: 1, 467: 3, 468: 3, 469: 2, 470: 1, 471: 1, 472: 1, 473: 1, 474: 1, 475: 1, 476: 1, 477: 1, 478: 1, 479: 3, 480: 1, 481: 1, 482: 1, 483: 1, 484: 2, 485: 1, 486: 1, 487: 2, 488: 2, 489: 1, 490: 6, 491: 1, 492: 1, 493: 3, 494: 2, 495: 8, 496: 1, 497: 1, 498: 1, 499: 1, 500: 2, 501: 3, 502: 2, 503: 2, 504: 1, 505: 8, 506: 4, 507: 2, 508: 3, 509: 1, 510: 5, 511: 1, 512: 1, 513: 1, 514: 1, 515: 4, 516: 1, 517: 3, 518: 1, 519: 1, 520: 1, 521: 1, 522: 1, 523: 1, 524: 2, 525: 2, 526: 1, 527: 4, 528: 2, 529: 3, 530: 1, 531: 1, 532: 2, 533: 1, 534: 5, 535: 2, 536: 1, 537: 1, 538: 1, 539: 1, 540: 2, 541: 3, 542: 1, 543: 3, 544: 6, 545: 5, 546: 5, 547: 1, 548: 1, 549: 1, 550: 1, 551: 1, 552: 1, 553: 1, 554: 1, 555: 3, 556: 2, 557: 1, 558: 2, 559: 4, 560: 4, 561: 3, 562: 1, 563: 5, 564: 2, 565: 1, 566: 1, 567: 1, 568: 1, 569: 1, 570: 4, 571: 1, 572: 1, 573: 1, 574: 1, 575: 1, 576: 1, 577: 1, 578: 1, 579: 1, 580: 1, 581: 1, 582: 1, 583: 1, 584: 2, 585: 1, 586: 1, 587: 1, 588: 1, 589: 1, 590: 2, 591: 1, 592: 1, 593: 1, 594: 1, 595: 1, 596: 1, 597: 1, 598: 1, 599: 1, 600: 1, 601: 4, 602: 1, 603: 3, 604: 1, 605: 1, 606: 1, 607: 1, 608: 2, 609: 2, 610: 1, 611: 1, 612: 1, 613: 1, 614: 2, 615: 1, 616: 1, 617: 1, 618: 1, 619: 1, 620: 1, 621: 1, 622: 2, 623: 1, 624: 1, 625: 1, 626: 2, 627: 1, 628: 2, 629: 1, 630: 1, 631: 1, 632: 1, 633: 2, 634: 1, 635: 6, 636: 1, 637: 4, 638: 1, 639: 4, 640: 1, 641: 2, 642: 1, 643: 4, 644: 5, 645: 1, 646: 9, 647: 3, 648: 1, 649: 1, 650: 3, 651: 4, 652: 2, 653: 1, 654: 1, 655: 2, 656: 1, 657: 1, 658: 4, 659: 2, 660: 2, 661: 2, 662: 1, 663: 1, 664: 1, 665: 2, 666: 1, 667: 1, 668: 3, 669: 1, 670: 1, 671: 1, 672: 1, 673: 1, 674: 2, 675: 1, 676: 1, 677: 1, 678: 1, 679: 1, 680: 1, 681: 1, 682: 1, 683: 1, 684: 1, 685: 1, 686: 1, 687: 1, 688: 1, 689: 1, 690: 1, 691: 2, 692: 4, 693: 2, 694: 1, 695: 3, 696: 1, 697: 1, 698: 1, 699: 1, 700: 1, 701: 2, 702: 1, 703: 1, 704: 1, 705: 2, 706: 1, 707: 1, 708: 1, 709: 3, 710: 1, 711: 1, 712: 4, 713: 1, 714: 2, 715: 2, 716: 1, 717: 1, 718: 2, 719: 1, 720: 1, 721: 5, 722: 1, 723: 2, 724: 2, 725: 2, 726: 2, 727: 1, 728: 3, 729: 1, 730: 1, 731: 1, 732: 2, 733: 1, 734: 3, 735: 1, 736: 1, 737: 4, 738: 1, 739: 10, 740: 1, 741: 1, 742: 1, 743: 3, 744: 2, 745: 1, 746: 1, 747: 1, 748: 1, 749: 2, 750: 1, 751: 2, 752: 2, 753: 1, 754: 8, 755: 10, 756: 1, 757: 1, 758: 1, 759: 1, 760: 1, 761: 1, 762: 2, 763: 1, 764: 1, 765: 1, 766: 1, 767: 1, 768: 1, 769: 2, 770: 1, 771: 2, 772: 5, 773: 6, 774: 1, 775: 1, 776: 1, 777: 1, 778: 1, 779: 1, 780: 1, 781: 3, 782: 1, 783: 1, 784: 1, 785: 1, 786: 1, 787: 1, 788: 1, 789: 2, 790: 1, 791: 1, 792: 1, 793: 1, 794: 1, 795: 1, 796: 1, 797: 1, 798: 1, 799: 1, 800: 1, 801: 1, 802: 1, 803: 1, 804: 1, 805: 1, 806: 1, 807: 6, 808: 1, 809: 1, 810: 1, 811: 1, 812: 1, 813: 1, 814: 1, 815: 1, 816: 1, 817: 1, 818: 1, 819: 1, 820: 1, 821: 1, 822: 1, 823: 1, 824: 1, 825: 1, 826: 1, 827: 1, 828: 1, 829: 1, 830: 1, 831: 1, 832: 1, 833: 1, 834: 1, 835: 1, 836: 4, 837: 1, 838: 1, 839: 1, 840: 1, 841: 5, 842: 1, 843: 1, 844: 1, 845: 1, 846: 1, 847: 1, 848: 2, 849: 2, 850: 1, 851: 1, 852: 2, 853: 1, 854: 1, 855: 3, 856: 2, 857: 1, 858: 1, 859: 2, 860: 3, 861: 2, 862: 1, 863: 1, 864: 1, 865: 1, 866: 1, 867: 1, 868: 1, 869: 1, 870: 2, 871: 1, 872: 2, 873: 1, 874: 2, 875: 1, 876: 3, 877: 2, 878: 2, 879: 4, 880: 2, 881: 1, 882: 4, 883: 2, 884: 1, 885: 1, 886: 1, 887: 1, 888: 1, 889: 1, 890: 1, 891: 1, 892: 1, 893: 1, 894: 1, 895: 1, 896: 1, 897: 1, 898: 1, 899: 1, 900: 1, 901: 4, 902: 5, 903: 1, 904: 1, 905: 1, 906: 1, 907: 1, 908: 1, 909: 1, 910: 1, 911: 1, 912: 1, 913: 1, 914: 1, 915: 1, 916: 1, 917: 2, 918: 1, 919: 2, 920: 1, 921: 1, 922: 1, 923: 1, 924: 1, 925: 2, 926: 1, 927: 1, 928: 2, 929: 1, 930: 4, 931: 2, 932: 2, 933: 1, 934: 1, 935: 4, 936: 1, 937: 2, 938: 4, 939: 1, 940: 1, 941: 1, 942: 1, 943: 4, 944: 1, 945: 1, 946: 1, 947: 1, 948: 1, 949: 2, 950: 1, 951: 1, 952: 1, 953: 1, 954: 1, 955: 1, 956: 1, 957: 3, 958: 1, 959: 1, 960: 1, 961: 2, 962: 1, 963: 1, 964: 1, 965: 1, 966: 1, 967: 2, 968: 3, 969: 2, 970: 1, 971: 1, 972: 1, 973: 1, 974: 1, 975: 1, 976: 1, 977: 1, 978: 1, 979: 1, 980: 1, 981: 1, 982: 1, 983: 1, 984: 1, 985: 1, 986: 1, 987: 1, 988: 1, 989: 1, 990: 1, 991: 1, 992: 2, 993: 8, 994: 2, 995: 4, 996: 2, 997: 1, 998: 1, 999: 2, 1000: 1, 1001: 1, 1002: 1, 1003: 1, 1004: 1, 1005: 1, 1006: 1, 1007: 1, 1008: 1, 1009: 1, 1010: 1, 1011: 1, 1012: 1, 1013: 1, 1014: 1, 1015: 1, 1016: 1, 1017: 7, 1018: 1, 1019: 1, 1020: 1, 1021: 1, 1022: 1, 1023: 1, 1024: 1, 1025: 1, 1026: 1, 1027: 2, 1028: 3, 1029: 3, 1030: 4, 1031: 1, 1032: 1, 1033: 3, 1034: 1, 1035: 1, 1036: 1, 1037: 2, 1038: 1, 1039: 1, 1040: 1, 1041: 1, 1042: 1, 1043: 2, 1044: 1, 1045: 2, 1046: 1, 1047: 1, 1048: 1, 1049: 1, 1050: 2, 1051: 1, 1052: 1, 1053: 1, 1054: 1, 1055: 13, 1056: 1, 1057: 1, 1058: 1, 1059: 1, 1060: 1, 1061: 1, 1062: 1, 1063: 1, 1064: 1, 1065: 2, 1066: 1, 1067: 1, 1068: 1, 1069: 1, 1070: 1, 1071: 1, 1072: 1, 1073: 1, 1074: 2, 1075: 1, 1076: 2, 1077: 1, 1078: 2, 1079: 1, 1080: 1, 1081: 2, 1082: 2, 1083: 1, 1084: 1, 1085: 1, 1086: 1, 1087: 1, 1088: 1, 1089: 1, 1090: 1, 1091: 1, 1092: 1, 1093: 1, 1094: 3, 1095: 1, 1096: 1, 1097: 1, 1098: 1, 1099: 1, 1100: 1, 1101: 1, 1102: 3, 1103: 1, 1104: 1, 1105: 1, 1106: 1, 1107: 1, 1108: 1, 1109: 1, 1110: 1, 1111: 1, 1112: 1, 1113: 1, 1114: 1, 1115: 1, 1116: 1, 1117: 1, 1118: 1, 1119: 1, 1120: 1, 1121: 2, 1122: 1, 1123: 3, 1124: 1, 1125: 3, 1126: 3, 1127: 2, 1128: 1, 1129: 1, 1130: 1, 1131: 1, 1132: 2, 1133: 1, 1134: 1, 1135: 1, 1136: 2, 1137: 2, 1138: 1, 1139: 1, 1140: 1, 1141: 1, 1142: 1, 1143: 1, 1144: 1, 1145: 1, 1146: 1, 1147: 5, 1148: 1, 1149: 1, 1150: 1, 1151: 2, 1152: 3, 1153: 3, 1154: 1, 1155: 1, 1156: 1, 1157: 1, 1158: 2, 1159: 1, 1160: 2, 1161: 1, 1162: 1, 1163: 1, 1164: 1, 1165: 1, 1166: 1, 1167: 1, 1168: 3, 1169: 1, 1170: 3, 1171: 1, 1172: 3, 1173: 1, 1174: 1, 1175: 2, 1176: 1, 1177: 3, 1178: 1, 1179: 1, 1180: 1, 1181: 1, 1182: 1, 1183: 1, 1184: 1, 1185: 1, 1186: 1, 1187: 1, 1188: 2, 1189: 1, 1190: 1, 1191: 2, 1192: 1, 1193: 3, 1194: 1, 1195: 2, 1196: 2, 1197: 1, 1198: 1, 1199: 1, 1200: 1, 1201: 1, 1202: 1, 1203: 3, 1204: 1, 1205: 2, 1206: 1, 1207: 1, 1208: 1, 1209: 1, 1210: 1, 1211: 1, 1212: 1, 1213: 1, 1214: 1, 1215: 1, 1216: 1, 1217: 1, 1218: 1, 1219: 1, 1220: 1, 1221: 1, 1222: 2, 1223: 4, 1224: 1, 1225: 1, 1226: 2, 1227: 1, 1228: 1, 1229: 2, 1230: 2, 1231: 2, 1232: 1, 1233: 1, 1234: 1, 1235: 1, 1236: 2, 1237: 1, 1238: 2, 1239: 1, 1240: 1, 1241: 1, 1242: 1, 1243: 2, 1244: 1, 1245: 3, 1246: 4, 1247: 1, 1248: 1, 1249: 3, 1250: 1, 1251: 1, 1252: 1, 1253: 1, 1254: 1, 1255: 1, 1256: 1, 1257: 1, 1258: 2, 1259: 2, 1260: 1, 1261: 4, 1262: 1, 1263: 1, 1264: 1, 1265: 1, 1266: 1, 1267: 2, 1268: 1, 1269: 1, 1270: 1, 1271: 1, 1272: 1, 1273: 1, 1274: 3, 1275: 1, 1276: 1, 1277: 1, 1278: 1, 1279: 1, 1280: 1, 1281: 1, 1282: 1, 1283: 1, 1284: 1, 1285: 1, 1286: 1, 1287: 1, 1288: 1, 1289: 1, 1290: 1, 1291: 7, 1292: 1, 1293: 1, 1294: 1, 1295: 1, 1296: 1, 1297: 1, 1298: 1, 1299: 1, 1300: 1, 1301: 2, 1302: 1, 1303: 1, 1304: 1, 1305: 1, 1306: 1, 1307: 1, 1308: 1, 1309: 1, 1310: 1, 1311: 1, 1312: 1, 1313: 1, 1314: 1, 1315: 1, 1316: 1, 1317: 1, 1318: 1, 1319: 5, 1320: 1, 1321: 4, 1322: 1, 1323: 2, 1324: 1, 1325: 5, 1326: 2, 1327: 1, 1328: 1, 1329: 1, 1330: 1, 1331: 1, 1332: 1, 1333: 1, 1334: 1, 1335: 1, 1336: 1, 1337: 1, 1338: 1, 1339: 1, 1340: 1, 1341: 1, 1342: 1, 1343: 1, 1344: 1, 1345: 1, 1346: 1, 1347: 1, 1348: 1, 1349: 1, 1350: 1, 1351: 1, 1352: 2, 1353: 1, 1354: 1, 1355: 1, 1356: 1, 1357: 1, 1358: 1, 1359: 1, 1360: 1, 1361: 1, 1362: 1, 1363: 1, 1364: 1, 1365: 2, 1366: 1, 1367: 1, 1368: 1, 1369: 1, 1370: 1, 1371: 1, 1372: 1, 1373: 1, 1374: 1, 1375: 1, 1376: 1, 1377: 1, 1378: 1, 1379: 1}]\n"
     ]
    }
   ],
   "source": [
    "document = [get_string_from_file('melos.txt')]\n",
    "dict = make_dictionary(document)\n",
    "print(make_BOW_vectors(document,dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uni-gramのbag-of-wordsの出現を素性とする関数\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "def make_BOW_onehot_vectors(documents,dictionary):\n",
    "    result_vectors = []\n",
    "    \n",
    "    for adocument in documents:\n",
    "        avector = {}\n",
    "        words = [token for token in t.tokenize(adocument,wakati=True)]\n",
    "        for entry in dictionary:\n",
    "            avector[dictionary[entry]] = 0\n",
    "        for word in words:\n",
    "            avector[dictionary[word]] = 1\n",
    "        result_vectors.append(avector)\n",
    "    return result_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'私': 1, 'は': 2, '秋田': 3, '犬': 4, 'が': 5, '大好き': 6, 'です': 7, '。': 8, 'の': 9, '好き': 10, 'な': 11, '苦手': 12, 'より': 13, '猫': 14, 'ほう': 15}\n",
      "[{1: 2, 2: 2, 3: 2, 4: 3, 5: 1, 6: 1, 7: 2, 8: 2, 9: 1, 10: 1, 11: 1, 12: 0, 13: 0, 14: 0, 15: 0}, {1: 1, 2: 1, 3: 0, 4: 2, 5: 2, 6: 0, 7: 2, 8: 2, 9: 1, 10: 1, 11: 0, 12: 1, 13: 1, 14: 1, 15: 1}]\n",
      "[{1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 0, 13: 0, 14: 0, 15: 0}, {1: 1, 2: 1, 3: 0, 4: 1, 5: 1, 6: 0, 7: 1, 8: 1, 9: 1, 10: 1, 11: 0, 12: 1, 13: 1, 14: 1, 15: 1}]\n"
     ]
    }
   ],
   "source": [
    "document1 = '私は秋田犬が大好きです。私の好きな犬は秋田犬です。'\n",
    "document2 = '私は犬が苦手です。犬より猫のほうが好きです。'\n",
    "documents = [document1,document2]\n",
    "dict = make_dictionary(documents) \n",
    "print(dict)\n",
    "print(make_BOW_vectors(documents,dict))\n",
    "print(make_BOW_onehot_vectors(documents,dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizerモジュールによる単語の出現頻度の文書ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizerモジュールの入力形式に変換する関数\n",
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "t = Tokenizer()\n",
    "\n",
    "def make_corpus(documents):\n",
    "    result_corpus = []\n",
    "    \n",
    "    for adocument in documents:\n",
    "        words = [token for token in t.tokenize(adocument,wakati=True)]\n",
    "        text = \" \".join(words)\n",
    "        result_corpus.append(text)\n",
    "    return result_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'私': 1, 'は': 2, '秋田': 3, '犬': 4, 'が': 5, '大好き': 6, 'です': 7, '。': 8, 'の': 9, '好き': 10, 'な': 11, '苦手': 12, 'より': 13, '猫': 14, 'ほう': 15}\n"
     ]
    }
   ],
   "source": [
    "document1 = '私は秋田犬が大好きです。私の好きな犬は秋田犬です。'\n",
    "document2 = '私は犬が苦手です。犬より猫のほうが好きです。'\n",
    "documents = [document1,document2]\n",
    "dict = make_dictionary(documents) \n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -p (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "# scikit-learnのアップグレード\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私 は 秋田 犬 が 大好き です 。 私 の 好き な 犬 は 秋田 犬 です 。', '私 は 犬 が 苦手 です 。 犬 より 猫 の ほう が 好き です 。']\n"
     ]
    }
   ],
   "source": [
    "document1 = '私は秋田犬が大好きです。私の好きな犬は秋田犬です。'\n",
    "document2 = '私は犬が苦手です。犬より猫のほうが好きです。'\n",
    "documents = [document1,document2]\n",
    "dict = make_corpus(documents) \n",
    "print(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['が 大好き です' 'が 好き です' 'が 苦手 です' 'です 犬 より' 'です 私 の' 'な 犬 は' 'の ほう が'\n",
      " 'の 好き な' 'は 犬 が' 'は 秋田 犬' 'ほう が 好き' 'より 猫 の' '大好き です 私' '好き な 犬'\n",
      " '犬 が 大好き' '犬 が 苦手' '犬 は 秋田' '犬 より 猫' '猫 の ほう' '私 の 好き' '私 は 犬' '私 は 秋田'\n",
      " '秋田 犬 が' '秋田 犬 です' '苦手 です 犬']\n",
      "[[1 0 0 0 1 1 0 1 0 2 0 0 1 1 1 0 1 0 0 1 0 1 1 1 0]\n",
      " [0 1 1 1 0 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 1]]\n",
      "  (0, 0)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 9)\t2\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 16)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 21)\t1\n",
      "  (0, 22)\t1\n",
      "  (0, 23)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 6)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 18)\t1\n",
      "  (1, 20)\t1\n",
      "  (1, 24)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1文字の単語を許容するように、token_patternを指定する\n",
    "#vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "vectorizer = CountVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b',ngram_range=(3,3))\n",
    "\n",
    "X = vectorizer.fit_transform(dict)\n",
    "new_X = vectorizer.transform(dict)\n",
    "\n",
    "print(vectorizer.get_feature_names_out(dict))\n",
    "\n",
    "print(X.toarray())\n",
    "print(new_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidVectorizerモジュールによるTF-IDFの文書ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['が' 'です' 'な' 'の' 'は' 'ほう' 'より' '大好き' '好き' '犬' '猫' '私' '秋田' '苦手']\n",
      "[[0.16701034 0.33402067 0.2347272  0.16701034 0.33402067 0.\n",
      "  0.         0.2347272  0.16701034 0.50103101 0.         0.33402067\n",
      "  0.4694544  0.        ]\n",
      " [0.4090901  0.4090901  0.         0.20454505 0.20454505 0.28748093\n",
      "  0.28748093 0.         0.20454505 0.4090901  0.28748093 0.20454505\n",
      "  0.         0.28748093]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b')\n",
    "X = vectorizer.fit_transform(dict)\n",
    "print(vectorizer.get_feature_names_out(dict))\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['が 大好き' 'が 好き' 'が 苦手' 'です 犬' 'です 私' 'な 犬' 'の ほう' 'の 好き' 'は 犬' 'は 秋田'\n",
      " 'ほう が' 'より 猫' '大好き です' '好き です' '好き な' '犬 が' '犬 です' '犬 は' '犬 より' '猫 の'\n",
      " '私 の' '私 は' '秋田 犬' '苦手 です']\n",
      "[[0.23562054 0.         0.         0.         0.23562054 0.23562054\n",
      "  0.         0.23562054 0.         0.47124108 0.         0.\n",
      "  0.23562054 0.         0.23562054 0.16764596 0.23562054 0.23562054\n",
      "  0.         0.         0.23562054 0.16764596 0.47124108 0.        ]\n",
      " [0.         0.28852505 0.28852505 0.28852505 0.         0.\n",
      "  0.28852505 0.         0.28852505 0.         0.28852505 0.28852505\n",
      "  0.         0.28852505 0.         0.20528795 0.         0.\n",
      "  0.28852505 0.28852505 0.         0.20528795 0.         0.28852505]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b',ngram_range=(2,2))\n",
    "X = vectorizer.fit_transform(dict)\n",
    "print(vectorizer.get_feature_names_out(dict))\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 22)\t0.4712410816220059\n",
      "  (0, 21)\t0.16764595538637136\n",
      "  (0, 20)\t0.23562054081100295\n",
      "  (0, 17)\t0.23562054081100295\n",
      "  (0, 16)\t0.23562054081100295\n",
      "  (0, 15)\t0.16764595538637136\n",
      "  (0, 14)\t0.23562054081100295\n",
      "  (0, 12)\t0.23562054081100295\n",
      "  (0, 9)\t0.4712410816220059\n",
      "  (0, 7)\t0.23562054081100295\n",
      "  (0, 5)\t0.23562054081100295\n",
      "  (0, 4)\t0.23562054081100295\n",
      "  (0, 0)\t0.23562054081100295\n",
      "  (1, 23)\t0.28852504515391525\n",
      "  (1, 21)\t0.20528794595426583\n",
      "  (1, 19)\t0.28852504515391525\n",
      "  (1, 18)\t0.28852504515391525\n",
      "  (1, 15)\t0.20528794595426583\n",
      "  (1, 13)\t0.28852504515391525\n",
      "  (1, 11)\t0.28852504515391525\n",
      "  (1, 10)\t0.28852504515391525\n",
      "  (1, 8)\t0.28852504515391525\n",
      "  (1, 6)\t0.28852504515391525\n",
      "  (1, 3)\t0.28852504515391525\n",
      "  (1, 2)\t0.28852504515391525\n",
      "  (1, 1)\t0.28852504515391525\n"
     ]
    }
   ],
   "source": [
    "new_X = vectorizer.transform(dict)\n",
    "print(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TruncatedSVDモジュールによるLSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私 は 秋田 犬 が 大好き です 。 私 の 好き な 犬 は 秋田 犬 です 。', '私 は 犬 が 苦手 です 。 犬 より 猫 の ほう が 好き です 。', '私 は 本 が 好き です 。 毎 日本 を 読み ます 。', '私 は 数学 が 苦手 です 。', '私 は 運動 が 得意 で 、 走る の が 速い です 。', '私 は 毎日 8 時間 寝 て い ます 。', '私 は 肉 と 魚 が 好き です 。 嫌い な 食べ物 は ピーマン です 。', '私 は 毎朝 電車 で 通勤 し て い ます 。 満員 電車 は 嫌い です 。', '今日 は いい 天気 です 。 日差し が まぶしい 。', '明日 は 雨 が 降る かも しれ ませ ん 。']\n"
     ]
    }
   ],
   "source": [
    "document1 = '私は秋田犬が大好きです。私の好きな犬は秋田犬です。'\n",
    "document2 = '私は犬が苦手です。犬より猫のほうが好きです。'\n",
    "document3 = '私は本が好きです。毎日本を読みます。'\n",
    "document4 = '私は数学が苦手です。'\n",
    "document5 = '私は運動が得意で、走るのが速いです。'\n",
    "document6 = '私は毎日8時間寝ています。'\n",
    "document7 = '私は肉と魚が好きです。嫌いな食べ物はピーマンです。'\n",
    "document8 = '私は毎朝電車で通勤しています。満員電車は嫌いです。'\n",
    "document9 = '今日はいい天気です。日差しがまぶしい。'\n",
    "document10 = '明日は雨が降るかもしれません。'\n",
    "\n",
    "documents = [document1,document2,document3,document4,document5,document6,document7,document8,document9,document10]\n",
    "dict = make_corpus(documents) \n",
    "print(dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 55)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(token_pattern='(?u)\\\\b\\\\w+\\\\b',sublinear_tf=True)\n",
    "X = vectorizer.fit_transform(dict)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6755768  -0.27843101 -0.26856757 -0.15989897  0.0218075   0.02213749\n",
      "  -0.28845168]\n",
      " [ 0.71449893 -0.3433819  -0.1981751  -0.12984158 -0.09676418 -0.21165462\n",
      "  -0.18046959]\n",
      " [ 0.46417642  0.19180123 -0.02346579  0.00973958  0.5915433  -0.27944632\n",
      "   0.53225773]\n",
      " [ 0.60150519 -0.11702002  0.07424716  0.04562569 -0.12410936 -0.26907464\n",
      "   0.06637754]\n",
      " [ 0.50587724 -0.02412961  0.11104759  0.03651477 -0.56674281  0.17880534\n",
      "   0.51882195]\n",
      " [ 0.26155699  0.7271639  -0.07386861 -0.08272002 -0.05679014 -0.32318865\n",
      "  -0.28471605]\n",
      " [ 0.53685042  0.01953388 -0.04135825  0.05270883  0.37642683  0.65475833\n",
      "  -0.08675934]\n",
      " [ 0.37314351  0.67744546 -0.02297382  0.01834065 -0.19158501  0.25951488\n",
      "  -0.0504354 ]\n",
      " [ 0.30515288 -0.07094008  0.48275125  0.75865618  0.04201366 -0.09557681\n",
      "  -0.22509902]\n",
      " [ 0.16987888 -0.02828892  0.79982474 -0.55717243  0.07426817  0.01609537\n",
      "  -0.1005188 ]]\n",
      "(10, 7)\n",
      "[0.03800946 0.15283318 0.12135128 0.12162206 0.114248   0.10813325\n",
      " 0.10634575]\n",
      "0.7625429675087397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=7,n_iter=5,random_state=42)\n",
    "newX = svd.fit_transform(X)\n",
    "print(newX)\n",
    "print(newX.shape)\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6755768  -0.27843101 -0.26856757]\n",
      " [ 0.71449893 -0.3433819  -0.1981751 ]\n",
      " [ 0.46417642  0.19180123 -0.02346579]\n",
      " [ 0.60150519 -0.11702002  0.07424716]\n",
      " [ 0.50587724 -0.02412961  0.11104759]\n",
      " [ 0.26155699  0.7271639  -0.07386861]\n",
      " [ 0.53685042  0.01953388 -0.04135825]\n",
      " [ 0.37314351  0.67744546 -0.02297382]\n",
      " [ 0.30515288 -0.07094008  0.48275125]\n",
      " [ 0.16987888 -0.02828892  0.79982474]]\n",
      "(10, 3)\n",
      "[0.03800946 0.15283318 0.12135128]\n",
      "0.3121939206181686\n"
     ]
    }
   ],
   "source": [
    "#次元数を減らしてみる\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=3,n_iter=5,random_state=42)\n",
    "newX = svd.fit_transform(X)\n",
    "print(newX)\n",
    "print(newX.shape)\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.6755768  -0.27843101 -0.26856757 -0.15989897  0.0218075   0.02213749\n",
      "  -0.28845168 -0.34876668  0.0521453  -0.39981071]\n",
      " [ 0.71449893 -0.3433819  -0.1981751  -0.12984158 -0.09676418 -0.21165462\n",
      "  -0.18046959 -0.05237183  0.13186961  0.45671138]\n",
      " [ 0.46417642  0.19180123 -0.02346579  0.00973958  0.5915433  -0.27944632\n",
      "   0.53225773 -0.16404332  0.09405809 -0.00615545]\n",
      " [ 0.60150519 -0.11702002  0.07424716  0.04562569 -0.12410936 -0.26907464\n",
      "   0.06637754  0.69900697  0.00339552 -0.18992348]\n",
      " [ 0.50587724 -0.02412961  0.11104759  0.03651477 -0.56674281  0.17880534\n",
      "   0.51882195 -0.22017632 -0.24293529  0.00097069]\n",
      " [ 0.26155699  0.7271639  -0.07386861 -0.08272002 -0.05679014 -0.32318865\n",
      "  -0.28471605 -0.06625953 -0.4433292   0.02917315]\n",
      " [ 0.53685042  0.01953388 -0.04135825  0.05270883  0.37642683  0.65475833\n",
      "  -0.08675934  0.20179022 -0.28182581  0.09403952]\n",
      " [ 0.37314351  0.67744546 -0.02297382  0.01834065 -0.19158501  0.25951488\n",
      "  -0.0504354   0.03390765  0.54149301  0.00254255]\n",
      " [ 0.30515288 -0.07094008  0.48275125  0.75865618  0.04201366 -0.09557681\n",
      "  -0.22509902 -0.17617125  0.02498751  0.00330535]\n",
      " [ 0.16987888 -0.02828892  0.79982474 -0.55717243  0.07426817  0.01609537\n",
      "  -0.1005188  -0.05759734  0.03131149  0.0018613 ]]\n",
      "(10, 10)\n",
      "[0.03800946 0.15283318 0.12135128 0.12162206 0.114248   0.10813325\n",
      " 0.10634575 0.09900369 0.08496247 0.05349088]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 次元数を増やしてみる\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=10,n_iter=5,random_state=42)\n",
    "newX = svd.fit_transform(X)\n",
    "print(newX)\n",
    "print(newX.shape)\n",
    "print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
