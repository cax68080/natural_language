{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08215ff9-b315-4403-9450-8d94ea756817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8a1c1e-a1f6-4a4d-8943-b4baadccdc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28358eebac334d9390c1346a6376ed6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\utils\\generic.py:339: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78cc02e6114426ca39926a02628b836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/381M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c1d4f612954cec9d4fb1c1c72c4638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/3.23M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11fe4d877f1e4f46beb2f9f25f074883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/326 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# llm-based-use.py\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"cyberagent/open-calm-small\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cyberagent/open-calm-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c7bd4fb-98e6-4d0e-acab-462d2a8a9d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'都心'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(\"横浜は東京の\",return_tensors=\"pt\")\n",
    "tokens = model.generate(**input,max_new_tokens=1,do_sample=False)\n",
    "tokenizer.decode(tokens[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b2115e7-1296-4915-917e-cb614424820a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 52096])\n",
      "1 都心 20.08707618713379\n",
      "2 「 19.630908966064453\n",
      "3 銀座 19.35006332397461\n",
      "4 ベッド 18.956317901611328\n",
      "5 駅前 18.71445083618164\n"
     ]
    }
   ],
   "source": [
    "out = model.generate(**input,max_new_tokens=1,return_dict_in_generate=True,output_scores=True)\n",
    "print(out.scores[0].shape)\n",
    "top5 = torch.topk(out.scores[0][0],5)\n",
    "for i in range(5):\n",
    "    print(i+1,tokenizer.decode(top5.indices[i]),top5.values[i].item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2213afd9-8924-494c-b572-22ae665f1ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'もうかりまっか?\\n「お、お、お、お、'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(\"もうかりまっか？\",return_tensors=\"pt\")\n",
    "tokens = model.generate(**input,max_new_tokens=10,do_sample=False)\n",
    "tokenizer.decode(tokens[0],skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "081894de-cf39-46d1-b10e-a8626689d626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'今日は天気がよいですね\\nそうですね\\nどこかへ行きましょうか。\\nさて、\\n今日は、\\n「  いい天気 」\\nです。\\n今日は、\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = tokenizer(\"今日は天気がよいですね\\n\" + \"そうですね\\n\" + \"どこかへ行きましょうか。\",return_tensors=\"pt\")\n",
    "tokens = model.generate(**input,max_new_tokens=20,do_sample=False)\n",
    "tokenizer.decode(tokens[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d7bc66c2-c295-4e0f-b26d-a6ab7cfa8261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generated_text': '東京は日本の首都である。\\n\\n歴史\\n古代には、古代のローマ・カトリック教会は、ローマ・カトリック教会のローマ教会と、ローマ・カトリック教会のローマ'}\n"
     ]
    }
   ],
   "source": [
    "# llm-based-use2.py\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer,pipeline\n",
    "\n",
    "model_id = \"cyberagent/open-calm-small\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "generator = pipeline(\"text-generation\",model=model,tokenizer=tokenizer)\n",
    "outs = generator(\"東京は日本の\",max_new_tokens=30)\n",
    "\n",
    "print(outs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65f12a02-5a74-4223-8381-759ee8665b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "東京は日本の首都である。\n",
      "\n",
      "歴史\n",
      "古代には、古代のローマ・カトリック教会は、ローマ・カトリック教会のローマ教会と、ローマ・カトリック教会のローマ\n"
     ]
    }
   ],
   "source": [
    "# llm-based-use3.py\n",
    "input = tokenizer(\"東京は日本の\",return_tensors=\"pt\")\n",
    "tokens = model.generate(**input,max_new_tokens=30)\n",
    "output = tokenizer.decode(tokens[0],skip_special_tokens=True)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d978784a-deb8-4ad8-9bc2-0a4dabbb9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "日本の漫画は、今、どこで作られているのか? そこで、\n",
      "この絵本のように、本のような絵本も作りたいなあと思い、本を出版しました。\n",
      "日本の漫画は、また、現代でも日本中の高校生に必ずと言っていいほど必読であると言える。\n",
      "日本の漫画は2,000万本を超えています。\n",
      "日本の漫画は、漫画の中で有名なキャラクターに擬人化して、オリジナルのアニメソングを制作しています。\n",
      "日本の漫画は、主に小学生向けに制作されたもの。\n"
     ]
    }
   ],
   "source": [
    "# llm-based-use4.py\n",
    "input = tokenizer(\"日本の漫画は\",return_tensors=\"pt\")\n",
    "tokens = model.generate(**input,max_new_tokens=30,eos_token_id=tokenizer.encode(\"。\"),pad_token_id=tokenizer.pad_token_id,do_sample=True,num_return_sequences=5)\n",
    "\n",
    "for i in range(5):\n",
    "    output = tokenizer.decode(tokens[i],skip_special_tokens=True)\n",
    "\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76e6a00-af06-4da8-a438-3b08a1e77fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
